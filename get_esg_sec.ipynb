{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edccaa6-5b20-4320-a59f-50b982098788",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install edgartools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5a292-66ef-4b57-ae7d-6929d212c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edgar import *\n",
    "from edgar.xbrl import *\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "set_identity(\"yiyi.xiao@barclays.com\")\n",
    "request_headers = {\n",
    "    'User-Agent': 'Barclays yiyi.xiao@barclays.com',\n",
    "    'Accept-Encoding': 'gzip, deflate',\n",
    "    'Host': 'www.sec.gov'\n",
    "}\n",
    "output_path = 'C:/Users/YXiao/Documents/Fin_Statements'\n",
    "persist_directory = 'C:/Users/YXiao/Downloads/'\n",
    "\n",
    "\n",
    "\n",
    "def download_filing_primary_document(company_ticker):\n",
    "    # # Get filing statement for a given date\n",
    "    # filing = Company(company_ticker).get_filings(form=\"10-K\", filing_date='2023-11-14:2024-11-13').get(0)\n",
    "    # Get the latest filing statement\n",
    "    filing = Company(company_ticker).get_filings(form=\"10-K\").latest(1)\n",
    "    print(filing)\n",
    "\n",
    "    # Download financial statements\n",
    "    # xbrl_data = filing.xbrl()\n",
    "    # statements = xbrl_data.statements\n",
    "\n",
    "    # statements['ConsolidatedBalanceSheets']\n",
    "    # statements['ConsolidatedBalanceSheets'].get_dataframe()\n",
    "    # statements['ConsolidatedStatementsofComprehensiveIncome'].get_dataframe()\n",
    "    # statements['ConsolidatedStatementsofCashFlows'].get_dataframe()\n",
    "\n",
    "    # Download the primary document to extract text\n",
    "    response = requests.get(filing.document.url, headers = request_headers)\n",
    "    if response.status_code != '200':\n",
    "        with open(f\"{output_path}/{company_ticker}_filing_content.html\", \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "            print(f'Downloaded {company_ticker}_filing_content.html')\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "\n",
    "\n",
    "def extract_text_from_filing(company_ticker):\n",
    "    file_path = f\"{output_path}/{company_ticker}_filing_content.html\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "    # Filter for meaningful text within specific tags\n",
    "    text_elements = []\n",
    "    for tag in soup.find_all(['p', 'div']):\n",
    "        if tag.text.strip():\n",
    "            text_elements.append(tag.get_text(strip=True))\n",
    "\n",
    "    # Filter for the business section text content\n",
    "    start_idx = None\n",
    "    end_idx = None\n",
    "    for i, t in enumerate(text_elements):\n",
    "        if 'Item 1' in t and 'Business' in t and len(t) < 20:\n",
    "            start_idx = i\n",
    "            end_idx = None\n",
    "        elif 'Item 1A' in t and 'Risk Factors' in t and len(t) < 25:\n",
    "            end_idx = i\n",
    "    text_elements = text_elements[start_idx:end_idx]\n",
    "\n",
    "    def useful_content(s):\n",
    "        try:\n",
    "            int(s)\n",
    "            return False\n",
    "        except:\n",
    "            ls = s.lower()\n",
    "            if 'table' in ls and 'of' in ls and 'contents' in ls and len(ls) < 20:\n",
    "                return False\n",
    "            return True\n",
    "    \n",
    "    text_elements = [t for t in text_elements if useful_content(t)]\n",
    "\n",
    "    text_elements = ' '.join(text_elements)\n",
    "    return text_elements\n",
    "\n",
    "\n",
    "def main():\n",
    "    sp_companies = pd.read_csv(r\"C:\\git\\GoGoAI-ClimateFin\\financials.csv\",\n",
    "                               usecols=['Symbol', 'Name', 'Sector'])\n",
    "    sp_companies.rename(columns={'Symbol': 'Ticker', 'Name': 'Company_Name'}, inplace=True)\n",
    "\n",
    "    docs = []  # List to store LangChain Document objects\n",
    "    \n",
    "    for i, row in sp_companies.iloc[:5].iterrows():\n",
    "        download_filing_primary_document(row.Ticker)\n",
    "        text_elements = extract_text_from_filing(row.Ticker)\n",
    "        print(text_elements)\n",
    "        doc = Document(page_content=text_elements, metadata={\"company_name\": row.Company_Name, \"ticker\": row.Ticker, \"sector\": row.Sector})\n",
    "        docs.append(doc)\n",
    "    print(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "581bf0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_element = extract_text_from_filing('MMM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d12182",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c0291",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ea50126",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_small = docs[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3efeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c05e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4411d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772de03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ad16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(api_key=\"YOUR_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6608b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory='C:/Users/YXiao/Documents/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"gpt-4o\"\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0,\n",
    "                api_key=\"YOUR_API_KEY\")\n",
    "llm.predict(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b195a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "064a11db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectordb.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16e1e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73941379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2afa248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectordb.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608594ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What's the name of the company with the best climate strategy and provide a summary of its environment/sustainability strategy in keywords and bullet points\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc442b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Company('TSLA').get_filings(form=\"10-K\").latest(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3bf0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filing = Company('TSLA').get_filings(form=\"10-K\").latest(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbrl_data = filing.xbrl()\n",
    "xbrl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9932bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = xbrl_data.statements\n",
    "statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements['ConsolidatedBalanceSheets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements['ConsolidatedBalanceSheets'].get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b8fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements['ConsolidatedStatementsofComprehensiveIncome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements['ConsolidatedStatementsofCashFlows']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
